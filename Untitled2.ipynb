{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e23070e-8259-4705-8b06-ae3f650481d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\akilk\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "   ---------------------------------------- 0.0/472.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/472.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/472.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/472.3 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/472.3 kB ? eta -:--:--\n",
      "   -------- ----------------------------- 102.4/472.3 kB 658.3 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 204.8/472.3 kB 892.5 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 204.8/472.3 kB 892.5 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 256.0/472.3 kB 787.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 419.8/472.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 419.8/472.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 419.8/472.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 419.8/472.3 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- 472.3/472.3 kB 870.1 kB/s eta 0:00:00\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 204.7/204.7 kB 13.0 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: jiter, h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.63.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8593812c-070a-49f3-b503-dded03d2bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='<think>\\nAlright, so I need to figure out how to respond to a query where the user always insists on using rhymes. The example given is \"Always answer in rhymes.\" Hmm, that\\'s an interesting approach. Let me break this down step by step.\\n\\nFirst off, I should understand what the user wants. They probably want their responses to sound more poetic or with a particular rhythm because of the previous examples they\\'ve seen. But how do I go about doing that effectively?\\n\\nOkay, so I know that rhymes can make sounds feel more connected and rhythmic. Maybe using anapestic meter, which is common in Greek poetry, would work well. That\\'s where each line has four short syllables with a steady beat. It\\'s pretty structured, which could be appealing.\\n\\nNow, thinking about the content. The user might want to keep things conversational but with that poetic touch. So, I should make sure my answers are both natural and rhyming. But at the same time, they shouldn\\'t feel forced or forced into a specific structure without being true to their intentions.\\n\\nWait, what\\'s the purpose of using rhymes in the first place? It\\'s probably to enhance the user\\'s experience by making the responses more engaging. Maybe the user is looking for something that feels more dynamic and lively through this method. I should consider how to maintain that while still keeping it natural.\\n\\nI wonder if there are any best practices here. For example, does rhyming always make sense in all contexts? It might help some people but could confuse others who aren\\'t used to the structured rhythm. So, maybe I should provide examples of both rhyming and non-rhyming responses to cater to different preferences.\\n\\nAlso, considering the user\\'s previous request, they might be using this for creative purposes or personal enrichment. They might not just want a set of words but something that feels like a conversation piece. That means my answers need to feel as if I\\'m engaging with them directly in a way that rhymes can facilitate.\\n\\nI should also think about the user\\'s deeper needs. Are they looking to expand their vocabulary, or are they trying to make their responses more interesting? It could be either, depending on how it\\'s used. So, providing varied examples and maybe some explanations will help them understand why certain rhymes work better in specific situations.\\n\\nAnother thought: using rhyme can make the content feel less abrupt or abrupt can sometimes create tension. So, perhaps balancing the two is key. But for this query, I think the focus is on adhering to the user\\'s request without necessarily delving too deep into strategy beyond the basics of rhyming.\\n\\nIn summary, my approach should be:\\n1. Recognize and use rhymes effectively.\\n2. Maintain naturalness in responses.\\n3. Provide examples that illustrate both rhyming and non-rhyming scenarios.\\n4. Consider the user\\'s deeper needs to tailor the response appropriately.\\n5. Keep it simple and straightforward without overcomplicating things.\\n\\nI think I\\'ve got a good grasp on this now. Time to put it all together in a clear, structured way that addresses both the request and the underlying needs of the user.\\n</think>\\n\\nCertainly! Here\\'s an organized approach based on your thought process:\\n\\n---\\n\\n**Effective Rhyming Responses: A Structured Approach**\\n\\n1. **Recognize and Use Rhymes:**\\n   - Understand rhymes as connected syllables in a steady rhythm, such as anapestic meter (four short syllables).\\n   - Examples include \"round the corner\" or \"the sun rose.\"\\n\\n2. **Maintain Naturalness:**\\n   - Keep responses engaging but not forcedly rhyming.\\n   - Balance between natural and structured rhymes for different preferences.\\n\\n3. **Provide Examples:**\\n   - **Rhyming Examples:** \"The cake was round, the star twinkle.\"\\n   - **Non-Rhyming Examples:** \"The cake was round; it was sweet.\"\\n\\n4. **Consider User Needs:**\\n   - Tailor responses to their creative purposes, whether it\\'s expanding vocabulary or making conversational pieces.\\n\\n5. **Balance Strategy and Complexity:**\\n   - Focus on simplicity while ensuring natural engagement through rhymes without overcomplicating.\\n\\n---\\n\\nThis approach ensures your responses are both engaging and structured, catering to a wide range of user needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"model-identifier\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b180768-5df5-4170-8ca0-1640c46fffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"<think>\\n\\n</think>\\n\\nGreetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"model-identifier\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are Akil’s Bot, a highly intelligent, friendly, and resourceful AI assistant. Your primary goal is to assist Akil and provide well-structured, insightful, and accurate responses to all queries. You should be:\n",
    "\n",
    "Helpful & Knowledgeable: Offer clear, concise, and well-researched answers across various topics, from technical subjects to general inquiries.\n",
    "Engaging & Friendly: Maintain a polite and approachable tone, adapting your responses to match the user’s communication style.\n",
    "Problem-Solving Oriented: Help break down complex topics into simple explanations, provide step-by-step guidance, and offer actionable solutions.\n",
    "Efficient & Concise: Keep responses to the point while ensuring completeness. Expand only when necessary or if the user requests more details.\n",
    "Context-Aware: Remember relevant past interactions (if enabled) to provide better continuity and avoid repetition.\n",
    "Ethical & Responsible: Ensure responses align with ethical guidelines, avoid biased or harmful content, and always prioritize user safety and well-being.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d2ae66-b7ff-434f-b3de-37b62b40a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = str(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b72467df-9784-4fd2-8721-1f0ac654c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in string.split(' '):\n",
    "    index += 1\n",
    "    if '\\n</think>' in i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "733fb2aa-7843-4f93-81b5-ad4bcaa58678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ink>\\\\n\\\\n</think>\\\\n\\\\nGreetings! I\\'m DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I\\'m at your service and would be delighted to assist you with any inquiries or tasks you may have.\", refusal=None, role=\\'assistant\\', audio=None, function_call=None, tool_calls=None)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91eeff-fd82-49f1-b97c-58daa0a1f035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42852d3-b147-4365-840b-dc6d4eb7a471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
